)
library(Assignment1KNN)
library(ggplot2) # Load ggplot2 to display plots
# Load the data included in the package
data(optdigits)
# Split the data (using a reproducible seed)
# This calls the split_optdigits_data function from your R/ folder
datasets <- split_optdigits_data(optdigits, seed = 12345)
# View the structure of the training data
# str(datasets$train_data)
# Find the best K
# 'datasets' variable was created in Task 1
k_search <- find_best_k(datasets$train_data, datasets$valid_data)
# Print the best K
print(paste("The best K found was:", k_search$best_k))
# Plot the error rate curve
# This calls the modified plot_knn_errors function from your R/ folder
plot_knn_errors(k_search$results_df, k_search$best_k)
# 1. Get the variables we need
best_k <- k_search$best_k
train_data <- datasets$train_data
# 2. Call our new function from the package
examples_8 <- find_hardest_easiest_8s(train_data, best_k)
# 3. Plot the examples using our new plot_digit() function
print(plot_digit(examples_8$hardest[1, ], title = "Hardest 1"))
print(plot_digit(examples_8$hardest[2, ], title = "Hardest 2"))
print(plot_digit(examples_8$hardest[3, ], title = "Hardest 3"))
print(plot_digit(examples_8$easiest[1, ], title = "Easiest 1"))
print(plot_digit(examples_8$easiest[2, ], title = "Easiest 2"))
# 1. Get the variables we need from previous chunks
best_k <- k_search$best_k
train_data <- datasets$train_data
valid_data <- datasets$valid_data
# --- 2. Create the TRAINING confusion matrix ---
fit_train_bestk <- kknn::kknn(Digit ~ ., train_data, train_data, k = best_k, kernel = "rectangular")
pred_train_bestk <- stats::fitted(fit_train_bestk)
cm_train <- table(Actual = train_data$Digit, Predicted = pred_train_bestk)
# --- 3. Create the VALIDATION confusion matrix ---
fit_valid_bestk <- kknn::kknn(Digit ~ ., train_data, valid_data, k = best_k, kernel = "rectangular")
pred_valid_bestk <- stats::fitted(fit_valid_bestk)
cm_valid <- table(Actual = valid_data$Digit, Predicted = pred_valid_bestk)
# --- 4. Plot Heatmap for TRAINING data ---
# (This calls the new function from your package)
print(plot_confusion_matrix(cm_train, title = "Training Set"))
# --- 5. Plot Heatmap for VALIDATION data ---
# (This calls the new function from yourVignetteBuilder: knitr package)
print(plot_confusion_matrix(cm_valid, title = "Validation Set"))
# Call the evaluate_on_test_set function from your R/ folder
final_evaluation <- evaluate_on_test_set(
train_data = datasets$train_data,
test_data = datasets$test_data,
best_k = k_search$best_k
)
# The function automatically prints the error rate and text-based confusion matrix.
# We will use the 'final_evaluation' variable in the next step to visualize it.
# 1. Extract the confusion matrix from the 'final_evaluation' list
#    (this variable was created in the 'task5' chunk)
my_matrix <- final_evaluation$confusion_matrix
# 2. Plot the heatmap using our package function
print(plot_confusion_matrix(my_matrix, title = "Test Set"))
devtools::document()
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(Assignment1KNN)
library(ggplot2) # Load ggplot2 to display plots
# Load the data included in the package
data(optdigits)
# Split the data (using a reproducible seed)
datasets <- split_optdigits_data(optdigits, seed = 12345)
# Store datasets in easy-to-use variables
train_data <- datasets$train_data
valid_data <- datasets$valid_data
test_data <- datasets$test_data
# Call our function from the R/ folder
k_30_results <- evaluate_k_30(train_data, test_data)
# Print misclassification rates
cat("--- Misclassification Rates (K=30) ---\n")
cat(paste("Training Error:", round(k_30_results$error_train, 5), "\n"))
cat(paste("Test Error:    ", round(k_30_results$error_test, 5), "\n\n"))
# Plot confusion matrices
cat("--- Confusion Matrices (K=30) ---\n")
print(plot_confusion_matrix(k_30_results$cm_train, title = "Training Set (K=30)"))
print(plot_confusion_matrix(k_30_results$cm_test, title = "Test Set (K=30)"))
# This code runs the analysis for Task 4 to get 'best_k'
k_search_misclass <- find_best_k_misclassification(train_data, valid_data)
best_k_misclass <- k_search_misclass$best_k
cat(paste("Note: The 'Best K' (from Task 4) is:", best_k_misclass, "\n"))
# Call our new function from the R/ folder
examples_8 <- find_hardest_easiest_8s(train_data, best_k_misclass)
# Plot the examples
print(plot_digit(examples_8$hardest[1, ], title = "Hardest 1 (Prob '8' = 0.0)"))
print(plot_digit(examples_8$hardest[2, ], title = "Hardest 2 (Prob '8' = 0.0)"))
print(plot_digit(examples_8$hardest[3, ], title = "Hardest 3 (Prob '8' = 0.333)"))
print(plot_digit(examples_8$easiest[1, ], title = "Easiest 1 (Prob '8' = 1.0)"))
print(plot_digit(examples_8$easiest[2, ], title = "Easiest 2 (Prob '8' = 1.0)"))
# We already ran the analysis in the chunk above ('task3-find-k-first').
# Now we just plot the results.
plot_knn_errors(k_search_misclass$results_df, best_k_misclass)
# 1. Get the error rates from our 'k_search_misclass' object
train_error_best_k <- k_search_misclass$results_df$train_error[best_k_misclass]
valid_error_best_k <- k_search_misclass$results_df$valid_error[best_k_misclass]
# 2. Calculate the Test Error using the optimal K
final_model <- kknn::kknn(Digit ~ ., train_data, test_data, k = best_k_misclass, kernel = "rectangular")
pred_test <- stats::fitted(final_model)
test_error_best_k <- sum(pred_test != test_data$Digit) / nrow(test_data)
# 3. Print comparison
cat(paste("--- Error Rates for Optimal K (K=", best_k_misclass, ") ---\n"))
cat(paste("Training Error:  ", round(train_error_best_k, 5), "\n"))
cat(paste("Validation Error:", round(valid_error_best_k, 5), "\n"))
cat(paste("Test Error:      ", round(test_error_best_k, 5), "\n"))
# Call our new function from the R/ folder
k_search_ce <- find_best_k_cross_entropy(train_data, valid_data)
best_k_ce <- k_search_ce$best_k
cat(paste("The best K using Cross-Entropy is:", best_k_ce, "\n"))
# Plot the results
plot(k_search_ce$results_df$K,
k_search_ce$results_df$valid_cross_entropy,
type = "b", # "b" means both points and lines
xlab = "K (Number of Neighbors)",
ylab = "Cross-Entropy Error",
main = "Cross-Entropy Error vs. K (Validation Set)",
col = "blue",
lwd = 2)
# Add a vertical line for the best K
abline(v = best_k_ce, col = "red", lty = 2)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(Assignment1KNN)
library(ggplot2) # Load ggplot2 to display plots
# Load the data included in the package
data(optdigits)
# Split the data (using a reproducible seed)
datasets <- split_optdigits_data(optdigits, seed = 12345)
# Store datasets in easy-to-use variables
train_data <- datasets$train_data
valid_data <- datasets$valid_data
test_data <- datasets$test_data
# Call our function from the R/ folder
k_30_results <- evaluate_k_30(train_data, test_data)
# Print misclassification rates
cat("--- Misclassification Rates (K=30) ---\n")
cat(paste("Training Error:", round(k_30_results$error_train, 5), "\n"))
cat(paste("Test Error:    ", round(k_30_results$error_test, 5), "\n\n"))
# Plot confusion matrices
cat("--- Confusion Matrices (K=30) ---\n")
print(plot_confusion_matrix(k_30_results$cm_train, title = "Training Set (K=30)"))
print(plot_confusion_matrix(k_30_results$cm_test, title = "Test Set (K=30)"))
# This code runs the analysis for Task 4 to get 'best_k'
k_search_misclass <- find_best_k_misclassification(train_data, valid_data)
best_k_misclass <- k_search_misclass$best_k
cat(paste("Note: The 'Best K' (from Task 4) is:", best_k_misclass, "\n"))
# Call our new function from the R/ folder
examples_8 <- find_hardest_easiest_8s(train_data, best_k_misclass)
# Plot the examples
print(plot_digit(examples_8$hardest[1, ], title = "Hardest 1 (Prob '8' = 0.0)"))
print(plot_digit(examples_8$hardest[2, ], title = "Hardest 2 (Prob '8' = 0.0)"))
print(plot_digit(examples_8$hardest[3, ], title = "Hardest 3 (Prob '8' = 0.333)"))
print(plot_digit(examples_8$easiest[1, ], title = "Easiest 1 (Prob '8' = 1.0)"))
print(plot_digit(examples_8$easiest[2, ], title = "Easiest 2 (Prob '8' = 1.0)"))
# We already ran the analysis in the chunk above ('task3-find-k-first').
# Now we just plot the results.
plot_knn_errors(k_search_misclass$results_df, best_k_misclass)
# 1. Get the error rates from our 'k_search_misclass' object
train_error_best_k <- k_search_misclass$results_df$train_error[best_k_misclass]
valid_error_best_k <- k_search_misclass$results_df$valid_error[best_k_misclass]
# 2. Calculate the Test Error using the optimal K
final_model <- kknn::kknn(Digit ~ ., train_data, test_data, k = best_k_misclass, kernel = "rectangular")
pred_test <- stats::fitted(final_model)
test_error_best_k <- sum(pred_test != test_data$Digit) / nrow(test_data)
# 3. Print comparison
cat(paste("--- Error Rates for Optimal K (K=", best_k_misclass, ") ---\n"))
cat(paste("Training Error:  ", round(train_error_best_k, 5), "\n"))
cat(paste("Validation Error:", round(valid_error_best_k, 5), "\n"))
cat(paste("Test Error:      ", round(test_error_best_k, 5), "\n"))
# Call our new function from the R/ folder
k_search_ce <- find_best_k_cross_entropy(train_data, valid_data)
best_k_ce <- k_search_ce$best_k
cat(paste("The best K using Cross-Entropy is:", best_k_ce, "\n"))
# Plot the results
plot(k_search_ce$results_df$K,
k_search_ce$results_df$valid_cross_entropy,
type = "b", # "b" means both points and lines
xlab = "K (Number of Neighbors)",
ylab = "Cross-Entropy Error",
main = "Cross-Entropy Error vs. K (Validation Set)",
col = "blue",
lwd = 2)
# Add a vertical line for the best K
abline(v = best_k_ce, col = "red", lty = 2)
#' Split the Optdigits Dataset
#' (Fulfills Task 1)
#'
#' @param data The complete data frame.
#' @param seed A random seed.
#' @return A list containing train_data, valid_data, and test_data.
#' @export
split_optdigits_data <- function(data, seed = 12345) {
set.seed(seed)
n <- nrow(data)
n_train <- floor(0.5 * n)
n_valid <- floor(0.25 * n)
indices <- sample(1:n)
train_data <- data[indices[1:n_train], ]
valid_data <- data[indices[(n_train + 1):(n_train + n_valid)], ]
test_data <- data[indices[(n_train + n_valid + 1):n], ]
cat("--- Data Splitting Results ---\n")
cat(paste("Training set size:", nrow(train_data), "\n"))
cat(paste("Validation set size:", nrow(valid_data), "\n"))
cat(paste("Test set size:", nrow(test_data), "\n"))
cat("------------------------------\n\n")
return(list(train_data = train_data, valid_data = valid_data, test_data = test_data))
}
#' Evaluate a K=30 Classifier
#' (Fulfills Task 2)
#'
#' @param train_data The training dataset.
#' @param test_data The test dataset.
#' @return A list containing confusion matrices and error rates.
#' @importFrom kknn kknn
#' @importFrom stats fitted
#' @export
evaluate_k_30 <- function(train_data, test_data) {
# Fit on training data, predict on training data
fit_train <- kknn::kknn(Digit ~ ., train_data, train_data, k = 30, kernel = "rectangular")
pred_train <- stats::fitted(fit_train)
cm_train <- table(Actual = train_data$Digit, Predicted = pred_train)
error_train <- sum(pred_train != train_data$Digit) / nrow(train_data)
# Fit on training data, predict on test data
fit_test <- kknn::kknn(Digit ~ ., train_data, test_data, k = 30, kernel = "rectangular")
pred_test <- stats::fitted(fit_test)
cm_test <- table(Actual = test_data$Digit, Predicted = pred_test)
error_test <- sum(pred_test != test_data$Digit) / nrow(test_data)
return(list(
cm_train = cm_train,
error_train = error_train,
cm_test = cm_test,
error_test = error_test
))
}
#' Find Hardest and Easiest Digit Examples
#' (Fulfills Task 3)
#'
#' @param train_data The training dataset.
#' @param best_k The optimal K value (from Task 4).
#' @return A list containing \code{hardest} (3 examples) and \code{easiest} (2 examples).
#' @importFrom kknn kknn
#' @export
find_hardest_easiest_8s <- function(train_data, best_k) {
indices_8 <- which(train_data$Digit == "8")
train_8s <- train_data[indices_8, ]
model_8s <- kknn::kknn(Digit ~ ., train_data, train_8s, k = best_k)
prob_of_8 <- model_8s$prob[, "8"]
results_8s <- data.frame(
original_index = indices_8,
prob_of_8 = prob_of_8
)
results_8s_sorted <- results_8s[order(results_8s$prob_of_8), ]
hardest_indices <- head(results_8s_sorted$original_index, 3)
easiest_indices <- tail(results_8s_sorted$original_index, 2)
return(list(
hardest = train_data[hardest_indices, ],
easiest = train_data[easiest_indices, ]
))
}
#' Plot a Single Digit
#' (Helper function for Task 3)
#'
#' @param digit_row A single row from the optdigits data frame.
#' @param title A title for the plot.
#' @return A ggplot object.
#' @importFrom tidyr pivot_longer
#' @importFrom rlang .data
#' @importFrom ggplot2 ggplot aes geom_tile scale_fill_gradient scale_y_reverse labs theme_void coord_fixed theme element_text
#' @export
plot_digit <- function(digit_row, title = "") {
pixel_vector <- as.numeric(digit_row[1:64])
digit_matrix <- matrix(pixel_vector, nrow = 8, ncol = 8, byrow = TRUE)
digit_df <- as.data.frame(digit_matrix)
digit_df$y <- 1:8
digit_long_df <- tidyr::pivot_longer(digit_df,
cols = -y,
names_to = "x",
values_to = "intensity")
digit_long_df$x <- as.integer(gsub("V", "", digit_long_df$x))
plot <- ggplot(digit_long_df, aes(x = .data$x, y = .data$y, fill = .data$intensity)) +
geom_tile(color = "black") +
scale_fill_gradient(low = "white", high = "black", limits = c(0, 16)) +
scale_y_reverse() +
coord_fixed() +
theme_void() +
labs(title = title) +
theme(plot.title = element_text(hjust = 0.5, face = "bold"))
return(plot)
}
#' Find Optimal K (Misclassification)
#' (Fulfills Task 4)
#'
#' @param train_data The training dataset.
#' @param valid_data The validation dataset.
#' @param k_values An integer vector.
#' @return A list containing \code{results_df} and \code{best_k}.
#' @importFrom kknn kknn
#' @importFrom stats fitted
#' @export
find_best_k_misclassification <- function(train_data, valid_data, k_values = 1:30) {
results <- data.frame(
K = k_values,
train_error = numeric(length(k_values)),
valid_error = numeric(length(k_values))
)
for (k in k_values) {
fit_train <- kknn::kknn(Digit ~ ., train_data, train_data, k = k, kernel = "rectangular")
pred_train <- stats::fitted(fit_train)
results$train_error[k] <- sum(pred_train != train_data$Digit) / nrow(train_data)
fit_valid <- kknn::kknn(Digit ~ ., train_data, valid_data, k = k, kernel = "rectangular")
pred_valid <- stats::fitted(fit_valid)
results$valid_error[k] <- sum(pred_valid != valid_data$Digit) / nrow(valid_data)
}
best_k_row <- results[which.min(results$valid_error), ]
best_k <- best_k_row$K
return(list(results_df = results, best_k = best_k))
}
#' Plot KNN Misclassification Error Curve
#' (Helper function for Task 4)
#'
#' @param k_results_df The data frame from \code{find_best_k_misclassification}.
#' @param best_k The optimal K value.
#' @return A ggplot object.
#' @importFrom tidyr pivot_longer
#' @importFrom rlang .data
#' @importFrom ggplot2 ggplot aes geom_line geom_point labs theme_minimal geom_vline annotate element_text theme scale_x_continuous margin
#' @export
plot_knn_errors <- function(k_results_df, best_k) {
results_long <- tidyr::pivot_longer(k_results_df,
cols = c("train_error", "valid_error"),
names_to = "Dataset",
values_to = "ErrorRate")
min_valid_error <- min(k_results_df$valid_error)
plot_k <- ggplot(results_long, aes(x = .data$K, y = .data$ErrorRate, color = .data$Dataset, group = .data$Dataset)) +
geom_line(linewidth = 1) +
geom_point(size = 2) +
geom_vline(xintercept = best_k, linetype = "dashed", color = "blue", linewidth = 1) +
annotate("text",
x = best_k + 1,
y = min_valid_error + 0.05,
label = paste("Best K =", best_k),
color = "brown",
size = 5,
angle = 0,
hjust = 0) +
labs(title = "K-Nearest Neighbors: Model Complexity",
subtitle = "Finding the optimal K (Misclassification Error)",
x = "K (Number of Neighbors)",
y = "Misclassification Rate") +
scale_x_continuous(breaks = seq(0, 30, by = 5)) +
theme_minimal() +
theme(
plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
plot.subtitle = element_text(size = 16, hjust = 0.5),
plot.margin = margin(t = 20, r = 10, b = 10, l = 10, unit = "pt"),
axis.title = element_text(size = 14),
axis.text = element_text(size = 12),
legend.title = element_text(size = 14),
legend.text = element_text(size = 12)
)
return(plot_k)
}
#' Find Optimal K (Cross-Entropy)
#' (Fulfills Task 5)
#'
#' @param train_data The training dataset.
#' @param valid_data The validation dataset.
#' @param k_values An integer vector.
#' @return A list containing \code{results_df} and \code{best_k}.
#' @importFrom kknn kknn
#' @export
find_best_k_cross_entropy <- function(train_data, valid_data, k_values = 1:30) {
results <- data.frame(
K = k_values,
valid_cross_entropy = numeric(length(k_values))
)
for (k in k_values) {
fit_valid <- kknn::kknn(Digit ~ ., train_data, valid_data, k = k)
# Get probabilities P(y_i | x_i) for the *true* class
# model$prob is [n_samples, n_classes]
# We need to match the true class (e.g., "8") to its probability column
true_class_indices <- as.integer(valid_data$Digit)
n_valid <- nrow(valid_data)
# Extract the probability of the *correct* class for each observation
prob_correct_class <- fit_valid$prob[cbind(1:n_valid, true_class_indices)]
# Add small constant to avoid log(0)
prob_correct_class_safe <- pmax(prob_correct_class, 1e-15)
# Calculate Cross-Entropy (Negative Log-Likelihood)
# CE = - (1/N) * sum(log(P(y_i | x_i)))
results$valid_cross_entropy[k] <- -mean(log(prob_correct_class_safe))
}
best_k_row <- results[which.min(results$valid_cross_entropy), ]
best_k <- best_k_row$K
return(list(results_df = results, best_k = best_k))
}
#' Plot a Confusion Matrix Heatmap
#' (Helper function for Task 2)
#'
#' @param cm A confusion matrix object (from \code{table()}).
#' @param title A string for the plot subtitle.
#' @return A ggplot object.
#' @importFrom ggplot2 ggplot aes geom_tile geom_text scale_fill_gradient scale_y_discrete labs theme theme_minimal element_text
#' @importFrom rlang .data
#' @export
plot_confusion_matrix <- function(cm, title = "Confusion Matrix") {
cm_df <- as.data.frame(cm)
heatmap_plot <- ggplot(data = cm_df, aes(x = .data$Predicted, y = .data$Actual, fill = .data$Freq)) +
geom_tile(color = "black") +
geom_text(aes(label = ifelse(.data$Freq == 0, "", .data$Freq)),
color = "black", size = 4) +
scale_fill_gradient(low = "white", high = "steelblue", name = "Count") +
scale_y_discrete(limits = rev) +
labs(
title = "Confusion Matrix Heatmap",
subtitle = paste("Data:", title),
x = "Predicted Digit",
y = "Actual Digit"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 20, face = "bold", hjust = 0.5),
plot.subtitle = element_text(size = 14, hjust = 0.5),
axis.title = element_text(size = 14),
axis.text = element_text(size = 12, face = "bold"),
legend.position = "right"
)
return(heatmap_plot)
}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
library(Assignment1KNN)
library(ggplot2) # Load ggplot2 to display plots
# Load the data included in the package
data(optdigits)
# Split the data (using a reproducible seed)
datasets <- split_optdigits_data(optdigits, seed = 12345)
# Store datasets in easy-to-use variables
train_data <- datasets$train_data
valid_data <- datasets$valid_data
test_data <- datasets$test_data
# Call our function from the R/ folder
k_30_results <- evaluate_k_30(train_data, test_data)
# Print misclassification rates
cat("--- Misclassification Rates (K=30) ---\n")
cat(paste("Training Error:", round(k_30_results$error_train, 5), "\n"))
cat(paste("Test Error:    ", round(k_30_results$error_test, 5), "\n\n"))
# Plot confusion matrices
cat("--- Confusion Matrices (K=30) ---\n")
print(plot_confusion_matrix(k_30_results$cm_train, title = "Training Set (K=30)"))
print(plot_confusion_matrix(k_30_results$cm_test, title = "Test Set (K=30)"))
# This code runs the analysis for Task 4 to get 'best_k'
k_search_misclass <- find_best_k_misclassification(train_data, valid_data)
best_k_misclass <- k_search_misclass$best_k
cat(paste("Note: The 'Best K' (from Task 4) is:", best_k_misclass, "\n"))
# Call our new function from the R/ folder
examples_8 <- find_hardest_easiest_8s(train_data, best_k_misclass)
# Plot the examples
print(plot_digit(examples_8$hardest[1, ], title = "Hardest 1 (Prob '8' = 0.0)"))
print(plot_digit(examples_8$hardest[2, ], title = "Hardest 2 (Prob '8' = 0.0)"))
print(plot_digit(examples_8$hardest[3, ], title = "Hardest 3 (Prob '8' = 0.333)"))
print(plot_digit(examples_8$easiest[1, ], title = "Easiest 1 (Prob '8' = 1.0)"))
print(plot_digit(examples_8$easiest[2, ], title = "Easiest 2 (Prob '8' = 1.0)"))
# We already ran the analysis in the chunk above ('task3-find-k-first').
# Now we just plot the results.
plot_knn_errors(k_search_misclass$results_df, best_k_misclass)
# 1. Get the error rates from our 'k_search_misclass' object
train_error_best_k <- k_search_misclass$results_df$train_error[best_k_misclass]
valid_error_best_k <- k_search_misclass$results_df$valid_error[best_k_misclass]
# 2. Calculate the Test Error using the optimal K
final_model <- kknn::kknn(Digit ~ ., train_data, test_data, k = best_k_misclass, kernel = "rectangular")
pred_test <- stats::fitted(final_model)
test_error_best_k <- sum(pred_test != test_data$Digit) / nrow(test_data)
# 3. Print comparison
cat(paste("--- Error Rates for Optimal K (K=", best_k_misclass, ") ---\n"))
cat(paste("Training Error:  ", round(train_error_best_k, 5), "\n"))
cat(paste("Validation Error:", round(valid_error_best_k, 5), "\n"))
cat(paste("Test Error:      ", round(test_error_best_k, 5), "\n"))
# Call our new function from the R/ folder
k_search_ce <- find_best_k_cross_entropy(train_data, valid_data)
best_k_ce <- k_search_ce$best_k
cat(paste("The best K using Cross-Entropy is:", best_k_ce, "\n"))
# Plot the results
plot(k_search_ce$results_df$K,
k_search_ce$results_df$valid_cross_entropy,
type = "b", # "b" means both points and lines
xlab = "K (Number of Neighbors)",
ylab = "Cross-Entropy Error",
main = "Cross-Entropy Error vs. K (Validation Set)",
col = "blue",
lwd = 2)
# Add a vertical line for the best K
abline(v = best_k_ce, col = "red", lty = 2)
devtools::install(build_vignettes = TRUE)
devtools::install(build_vignettes = TRUE)
devtools::install(build_vignettes = TRUE)
devtools::install(build_vignettes = TRUE)
devtools::install(build_vignettes = TRUE)
browseVignettes("Assignment1.KNN")
devtools::install(build_vignettes = TRUE)
browseVignettes('Assignment1.KNN')
browseVignettes('Assignment1KNN')
